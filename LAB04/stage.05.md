### Fase 5: Identificar pods con recursos mal definidos

---

### ğŸ¯ Objetivo

Detectar pods que no tienen lÃ­mites o peticiones de recursos establecidos correctamente, lo que puede afectar a la estabilidad y predictibilidad del clÃºster.

---

### ğŸ§° Requisitos

* ClÃºster en funcionamiento con mÃºltiples pods
* `kubectl` y `metrics-server` instalados
* Conocimientos bÃ¡sicos de `resources.requests` y `resources.limits`

---

### ğŸ”§ Pasos

1. Listar todos los pods con sus namespaces:

   ```bash
   kubectl get pods -A
   ```

2. Inspeccionar los recursos de un pod:

   ```bash
   kubectl get pod <nombre> -n <namespace> -o jsonpath='{.spec.containers[*].resources}'
   ```

3. Alternativamente, usar `kubectl describe pod` y buscar la secciÃ³n de recursos:

   ```bash
   kubectl describe pod <nombre> -n <namespace>
   ```

4. Identificar pods sin `requests` ni `limits` definidos:

   * `requests: null`
   * `limits: null` o ausentes

5. Revisar el consumo real con `kubectl top` y comparar con la configuraciÃ³n declarada.

---

### ğŸ”¥ Retos

* **Encuentra todos los pods sin `limits` definidos en todo el clÃºster**
  ğŸ’¡ Usa un bucle como:

  ```bash
  kubectl get pods -A -o json | jq '.items[] | select(.spec.containers[].resources.limits == null) | .metadata.name'
  ```

* **Implementa una polÃ­tica que exija definir lÃ­mites con `LimitRange`**
  ğŸ’¡ Aplica un `LimitRange` en un namespace y lanza un pod sin definir recursos.

* **Compara dos pods idÃ©nticos, uno con lÃ­mites ajustados y otro sin ellos, bajo carga**
  ğŸ’¡ Lanza ambos y monitorea con `kubectl top`.

---

### âœ… Validaciones

* Se han identificado pods sin `requests` o `limits` definidos
* Se comprende el impacto de no configurar correctamente los recursos
* Se ha validado al menos un ejemplo de consumo excesivo debido a ausencia de lÃ­mites
