### Fase 2: Drenar nodo y observar redistribuciÃ³n de pods

---

### ğŸ¯ Objetivo

Aprender a realizar el drenado de un nodo para evacuar sus pods de forma segura y observar cÃ³mo Kubernetes reubica automÃ¡ticamente los workloads en otros nodos disponibles.

---

### ğŸ§° Requisitos

* ClÃºster con al menos 2 nodos
* Workloads en ejecuciÃ³n (Deployment o ReplicaSet con varias rÃ©plicas)
* Acceso a `kubectl` con privilegios de administraciÃ³n

---

### ğŸ”§ Pasos

1. Identificar el nodo a drenar:

   ```bash
   kubectl get nodes
   ```

2. Observar quÃ© pods estÃ¡n corriendo en ese nodo:

   ```bash
   kubectl get pods -o wide
   ```

3. Drenar el nodo:

   ```bash
   kubectl drain <nombre-del-nodo> --ignore-daemonsets --delete-emptydir-data
   ```

4. Comprobar que los pods han sido reprogramados en otros nodos:

   ```bash
   kubectl get pods -o wide
   ```

5. Volver a habilitar el nodo (si se desea):

   ```bash
   kubectl uncordon <nombre-del-nodo>
   ```

---

### ğŸ”¥ Retos

* **Lanza un Deployment con 5 rÃ©plicas y observa cÃ³mo se redistribuyen tras el drenado**
  ğŸ’¡ Usa `kubectl get pods -o wide` antes y despuÃ©s para comparar nodos asignados.

* **Detecta quÃ© pods no se reprograman automÃ¡ticamente y por quÃ©**
  ğŸ’¡ Algunos pods con `emptyDir`, sin controller, o con nodos especÃ­ficos pueden fallar.

* **Simula un mantenimiento parcial marcando como `cordon` antes de `drain`**
  ğŸ’¡ Esto evita que se programen nuevos pods mientras se evacÃºan los existentes.

---

### âœ… Validaciones

* El nodo ha sido drenado sin errores y los pods se han reubicado correctamente
* Los DaemonSets no se han eliminado durante el proceso
* El nodo puede volver a estar operativo tras `uncordon` y `kubectl get nodes` muestra estado `Ready`
